{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8598330,"sourceType":"datasetVersion","datasetId":5144075},{"sourceId":8600460,"sourceType":"datasetVersion","datasetId":5144087}],"dockerImageVersionId":30716,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install ultralytics\n!pip install albumentations opencv-python","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport shutil\nfrom random import shuffle\nfrom shutil import copyfile\nimport albumentations as A\nimport cv2\n\ndef augment_image(image_path):\n    image = cv2.imread(image_path)\n    transform = A.Compose([\n        A.RandomBrightnessContrast(p=0.2),\n        A.GaussNoise(p=0.2),\n        A.GaussianBlur(p=0.2),\n        A.Sharpen(p=0.2),\n        A.RandomGamma(p=0.2),\n        A.CLAHE(p=0.2)\n    ])\n    augmented = transform(image=image)\n    return augmented['image']\n\ndef save_augmented_image(image, dest_path):\n    cv2.imwrite(dest_path, image)\n\ndef augment_and_save(image_path, label_path, image_dest, label_dest):\n    image = cv2.imread(image_path)\n    augmented_image = augment_image(image_path)\n    save_augmented_image(augmented_image, image_dest)\n    shutil.copyfile(label_path, label_dest)\n\ndef split_data(train_ratio, test_ratio, directory, root_directory):\n    extensions = ['jpg', 'webp', 'JPG', 'jpeg']\n\n    # Create subdirectories\n    os.makedirs(os.path.join(directory, \"datasets/images\", \"train\"), exist_ok=True)\n    os.makedirs(os.path.join(directory, \"datasets/images\", \"valid\"), exist_ok=True)\n    os.makedirs(os.path.join(directory, \"datasets/images\", \"test\"), exist_ok=True)\n    \n    os.makedirs(os.path.join(directory, \"datasets/labels\", \"train\"), exist_ok=True)\n    os.makedirs(os.path.join(directory, \"datasets/labels\", \"valid\"), exist_ok=True)\n    os.makedirs(os.path.join(directory, \"datasets/labels\", \"test\"), exist_ok=True)\n    \n    image_files = [f for f in os.listdir(root_directory) if any(f.endswith(ext) for ext in extensions)]\n    \n    shuffle(image_files)\n    \n    total_samples = len(image_files)\n    train_split = int(train_ratio * total_samples)\n    valid_split = int((1 - (train_ratio + test_ratio)) * total_samples)\n    \n    train_files = image_files[:train_split]\n    valid_files = image_files[train_split:train_split + valid_split]\n    test_files = image_files[train_split + valid_split:]\n    \n    def copy_files(file_list, split, augment=False):\n        for file in file_list:\n            for ext in extensions:\n                if file.endswith(ext):\n                    base_file = file.rsplit('.', 1)[0]\n                    image_src = os.path.join(root_directory, file)\n                    image_dest = os.path.join(directory, f\"datasets/images/{split}\", file)\n                    label_src = os.path.join(root_directory, base_file + '.txt')\n                    label_dest = os.path.join(directory, f\"datasets/labels/{split}\", base_file + '.txt')\n                    \n                    copyfile(image_src, image_dest)\n                    if os.path.exists(label_src):\n                        copyfile(label_src, label_dest)\n                    \n                    if augment:\n                        augmented_image_dest = os.path.join(directory, f\"datasets/images/{split}\", base_file + '_aug.jpg')\n                        augmented_label_dest = os.path.join(directory, f\"datasets/labels/{split}\", base_file + '_aug.txt')\n                        augment_and_save(image_src, label_src, augmented_image_dest, augmented_label_dest)\n    \n    copy_files(train_files, 'train', augment=True)\n    copy_files(valid_files, 'valid', augment=False)\n    copy_files(test_files, 'test', augment=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"split_data(train_ratio=0.8, test_ratio=0.1, directory='/kaggle/working/',root_directory=\"/kaggle/input/traffic-signs-and-lights-in-yolo-format/Zavrsni\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from ultralytics import YOLO\n\nos.environ['WANDB_DISABLED'] = 'true'\nmodel = YOLO(\"yolov8x.pt\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"config_content = \"\"\"path: /kaggle/working/datasets\ntrain: images/train\nval: images/valid\ntest: images/test\n\n# Classes\nnames:\n  0: traffic_sign\n  1: traffic_light\n\"\"\"\nwith open(\"/kaggle/working/data_config.yaml\", \"w\") as f:\n    f.write(config_content)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.train(data=\"/kaggle/working/data_config.yaml\", epochs=200)\nmetrics = model.val()\npath = model.export(format=\"onnx\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metrics = model.val()\nprint(metrics.box.map) \nprint(metrics.box.map50)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metrics = model.val(split='test')\nprint(metrics.box.map)\nprint(metrics.box.map50)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results = model.predict(\"/kaggle/working/datasets/images/test/\", save=True, conf=0.5)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"folder being saved: \",results[0].save_dir)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"detect_folder = results[0].save_dir\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\ndef show_images_from_folder(folder_path,detect_folder):\n    extensions = ['jpg', 'JPG', 'jpeg', 'webp']\n    image_files = [os.path.join(detect_folder,f) for f in os.listdir(folder_path) if any(f.endswith(ext) for ext in extensions)]\n\n    selected_images = image_files[:8]\n\n    fig, axes = plt.subplots(2, 4, figsize=(12, 6))\n\n    for i, image_file in enumerate(selected_images):\n        row, col = divmod(i, 4)\n        img_path = image_file\n        img = mpimg.imread(img_path)\n        axes[row, col].imshow(img)\n        axes[row, col].axis('off')\n        axes[row, col].set_title(image_file)\n\n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_images_from_folder(\"/kaggle/working/datasets/images/test/\",detect_folder)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport matplotlib.pyplot as plt\n\nimage_path = '/kaggle/input/showcase-pics/0007.jpg'\n\nimage = cv2.imread(image_path)\n\nresults = model.predict(source=image, show=False)\n\nplt.figure(figsize=(10, 10))\nplt.imshow(cv2.cvtColor(results[0].plot(), cv2.COLOR_BGR2RGB))\nplt.axis('off')\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nfrom IPython.display import Video\n\n\nvideo_path = '/kaggle/input/showcase-pics/0011.webm'\noutput_path = '/kaggle/working/output_video.mp4'\n\nvideo = cv2.VideoCapture(video_path)\n\nif not video.isOpened():\n    print(\"Error: Could not open video.\")\nelse:\n    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n    out = cv2.VideoWriter(output_path, fourcc, 20.0, (int(video.get(3)), int(video.get(4))))\n\n    while video.isOpened():\n        ret, frame = video.read()\n        if ret:\n            results = model.predict(source=frame, show=False)\n            \n            processed_frame = results[0].plot()\n            \n            processed_frame = cv2.cvtColor(processed_frame, cv2.COLOR_RGB2BGR)\n            \n            out.write(processed_frame)\n        else:\n            break\n\n    video.release()\n    out.release()\n\n    print(\"Video processing complete. Output saved at:\", output_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install -r requirements.txt","metadata":{},"execution_count":null,"outputs":[]}]}